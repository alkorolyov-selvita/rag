{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-19T04:57:58.200677Z",
     "start_time": "2025-10-19T04:57:56.233548Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from rag.embeddings import LocalEmbedder\n",
    "\n",
    "ds = load_dataset(\"rag-datasets/rag-mini-bioasq\", \"text-corpus\")['passages']\n",
    "test_ds = load_dataset(\"rag-datasets/rag-mini-bioasq\", \"question-answer-passages\")['test']"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T04:58:01.749623Z",
     "start_time": "2025-10-19T04:57:58.203964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# embedder = LocalEmbedder(\"BAAI/bge-large-en-v1.5\", device='cuda')\n",
    "# embedder = LocalEmbedder(\"BAAI/bge-small-en-v1.5\", device='cuda')\n",
    "# embedder = LocalEmbedder(\"Qwen/Qwen3-Embedding-8B\", device='cuda')\n",
    "embedder = LocalEmbedder(\"Qwen/Qwen3-Embedding-4B\", device='cuda', model_kwargs={\"dtype\": torch.bfloat16})\n",
    "# embedder = LocalEmbedder(\"Qwen/Qwen3-Embedding-0.6B\", device='cuda', model_kwargs={\"dtype\": torch.bfloat16})"
   ],
   "id": "685639e9d9b31b4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 85.51it/s]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T04:58:28.720077Z",
     "start_time": "2025-10-19T04:58:18.601417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# assumes you already have your embedder\n",
    "tokenizer = embedder.model.tokenizer\n",
    "\n",
    "def get_seq_lengths(ds, column=\"passage\"):\n",
    "    lengths = []\n",
    "    for text in tqdm(ds[column], desc=\"Tokenizing\"):\n",
    "        tokens = tokenizer(text, truncation=False, padding=False, return_length=True)\n",
    "        lengths.append(tokens[\"length\"][0])\n",
    "    return pd.Series(lengths)\n",
    "\n",
    "# Example usage\n",
    "ds_lengths = get_seq_lengths(ds, column=\"passage\")"
   ],
   "id": "cdbdf73570de154c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing: 100%|██████████| 40221/40221 [00:10<00:00, 3989.56it/s]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T04:58:29.598788Z",
     "start_time": "2025-10-19T04:58:29.586560Z"
    }
   },
   "cell_type": "code",
   "source": "ds_lengths.describe()",
   "id": "3fcadf8b907c1f9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    40221.000000\n",
       "mean       249.147460\n",
       "std        233.892122\n",
       "min          2.000000\n",
       "25%          2.000000\n",
       "50%        267.000000\n",
       "75%        387.000000\n",
       "max       9579.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T04:56:10.085417Z",
     "start_time": "2025-10-19T04:53:37.408677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def embed(batch, column):\n",
    "    embs = embedder.embed_batch(batch[column])\n",
    "    return {'embedding': embs}\n",
    "\n",
    "ds = ds.map(\n",
    "    embed,\n",
    "    batch_size=8,\n",
    "    batched=True,\n",
    "    fn_kwargs={'column': 'passage'},\n",
    ")\n",
    "test_ds = test_ds.map(\n",
    "    embed,\n",
    "    batch_size=8,\n",
    "    batched=True,\n",
    "    fn_kwargs={'column': 'question'},\n",
    ")"
   ],
   "id": "5bb983ad9a5b1e23",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 100.62it/s]\n",
      "Map:  15%|█▌        | 6160/40221 [02:10<11:58, 47.38 examples/s] \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ds = ds.add_faiss_index(\n",
    "    column='embedding',\n",
    "    string_factory='Flat',\n",
    "    metric_type=faiss.METRIC_INNER_PRODUCT,\n",
    "    batch_size=128,\n",
    ")"
   ],
   "id": "8a4dee1d7ea95c18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Precompute vals",
   "id": "dee36ccc8fc16427"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "passage_id_to_text = ds.select_columns(['id', 'passage']).to_pandas().set_index('id')['passage'].to_dict()\n",
    "index_to_passage_id = np.array(ds['id'])\n",
    "queries = np.array(test_ds['question'])\n",
    "\n",
    "gold_sets = [np.array(eval(gold)) for gold in test_ds['relevant_passage_ids']]\n",
    "gold_counts = [len(s) for s in gold_sets]"
   ],
   "id": "663cbc5096f5c045",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Search",
   "id": "5ded4f160b9c0ce5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "k = 5\n",
    "res = ds.get_index('embedding').search_batch(np.array(test_ds['embedding']), k=k)\n",
    "retrieved_ids = index_to_passage_id[res.total_indices]\n",
    "retrieved_ids"
   ],
   "id": "9f807005f606568a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Metrics",
   "id": "84a3a46d3bc77465"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def precision_at_k(hit_flags):\n",
    "    return float(hit_flags.mean(axis=1).mean())\n",
    "\n",
    "def recall_at_k(hit_flags, gold_counts):\n",
    "    retrieved = hit_flags.sum(axis=1)\n",
    "    recall = retrieved / gold_counts\n",
    "    return float(recall.mean())\n",
    "\n",
    "def mrr_at_k(hit_flags):\n",
    "    has_hit = hit_flags.any(axis=1)\n",
    "    ranks = np.argmax(hit_flags, axis=1) + 1\n",
    "    reciprocal = np.zeros_like(ranks, dtype=np.float32)\n",
    "    reciprocal[has_hit] = 1.0 / ranks[has_hit]\n",
    "    return float(reciprocal.mean())\n",
    "\n",
    "def ndcg_at_k(hit_flags: np.ndarray) -> float:\n",
    "    # Binary relevance (1 if retrieved id is in gold set)\n",
    "    # DCG = sum_{i=1..k} (rel_i / log2(i+1)), since rel∈{0,1} we can simplify\n",
    "    k = hit_flags.shape[1]\n",
    "    discounts = 1.0 / np.log2(np.arange(2, k+2))  # [1/log2(2), 1/log2(3), ...]\n",
    "    dcg = (hit_flags * discounts).sum(axis=1)\n",
    "    # Ideal DCG for binary relevance = sum of top min(k, |gold|) discounts\n",
    "    # We need |gold| per query:\n",
    "    ndcg = dcg / np.array([discounts[:min(k, c)].sum() if c > 0 else 1.0\n",
    "                           for c in gold_counts])\n",
    "    return float(ndcg.mean())\n",
    "\n",
    "def get_hit_flags(retrieved_ids):\n",
    "    hit_flags = np.zeros_like(retrieved_ids, dtype=np.bool)\n",
    "    for i in range(len(retrieved_ids)):\n",
    "        hit_flags[i] = np.isin(retrieved_ids[i], gold_sets[i])\n",
    "    return hit_flags\n",
    "\n",
    "# hit_flags = get_hit_flags(retrieved_ids)\n",
    "\n",
    "def print_metrics(retrieved_ids, gold_counts, k):\n",
    "    hit_flags = get_hit_flags(retrieved_ids)\n",
    "\n",
    "    print(f'Embedding model: {embedder.model_name}')\n",
    "    print(f\"P@{k}:    {precision_at_k(hit_flags):.3f}\")\n",
    "    print(f\"R@{k}:    {recall_at_k(hit_flags, gold_counts):.3f}\")\n",
    "    print(f\"MRR@{k}:  {mrr_at_k(hit_flags):.3f}\")\n",
    "    print(f\"nDCG@{k}: {ndcg_at_k(hit_flags):.3f}\")\n",
    "\n",
    "print_metrics(retrieved_ids, gold_counts, k)"
   ],
   "id": "e6915d9d5e1e9c54",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a05e2193962063cf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
