{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-13T04:28:51.651631Z",
     "start_time": "2025-10-13T04:28:50.987380Z"
    }
   },
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T04:30:14.680089Z",
     "start_time": "2025-10-13T04:30:14.677906Z"
    }
   },
   "cell_type": "code",
   "source": "torch.__version__",
   "id": "4d105e582e1ba041",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0+cu128'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T04:37:49.916095Z",
     "start_time": "2025-10-13T04:37:49.914069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "id": "dcfe77324190d019",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T04:33:16.035509Z",
     "start_time": "2025-10-13T04:31:14.764498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.to(device)"
   ],
   "id": "1c2aff410d03d37b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ergot/projects/rag/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 4 files: 100%|██████████| 4/4 [01:55<00:00, 28.94s/it] \n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(152064, 3584)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=3584, out_features=3584, bias=True)\n",
       "          (k_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
       "          (o_proj): Linear(in_features=3584, out_features=3584, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "          (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "          (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T04:34:11.186065Z",
     "start_time": "2025-10-13T04:34:10.690757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer"
   ],
   "id": "ec9084bcc23eb8b8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T04:41:47.330096Z",
     "start_time": "2025-10-13T04:41:47.327444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"Help me prepare for my Senior AI developer interview\"\n",
    "\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    conversation,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "\n",
    "text"
   ],
   "id": "7dd82eb2ff319e13",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nHelp me prepare for my Senior AI developer interview<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T04:41:51.278803Z",
     "start_time": "2025-10-13T04:41:51.275043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "model_inputs"
   ],
   "id": "5f4784084cfa5cb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151644,   8948,    198,   2610,    525,   1207,  16948,     11,   3465,\n",
       "            553,  54364,  14817,     13,   1446,    525,    264,  10950,  17847,\n",
       "             13, 151645,    198, 151644,    872,    198,  12689,    752,  10549,\n",
       "            369,    847,  19342,  15235,  15754,   7128, 151645,    198, 151644,\n",
       "          77091,    198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T04:44:37.513859Z",
     "start_time": "2025-10-13T04:44:26.388573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tic = time.time()\n",
    "generated_ids = model.generate(**model_inputs, max_new_tokens=512)\n",
    "toc = time.time()\n",
    "\n"
   ],
   "id": "aa475e478f676b2a",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "80cd9bbb1dc50de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T04:44:42.100709Z",
     "start_time": "2025-10-13T04:44:42.097912Z"
    }
   },
   "cell_type": "code",
   "source": "model_inputs.input_ids",
   "id": "51f4f78991141ad1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[151644,   8948,    198,   2610,    525,   1207,  16948,     11,   3465,\n",
       "            553,  54364,  14817,     13,   1446,    525,    264,  10950,  17847,\n",
       "             13, 151645,    198, 151644,    872,    198,  12689,    752,  10549,\n",
       "            369,    847,  19342,  15235,  15754,   7128, 151645,    198, 151644,\n",
       "          77091,    198]], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T04:46:51.205173Z",
     "start_time": "2025-10-13T04:46:51.199775Z"
    }
   },
   "cell_type": "code",
   "source": "generated_ids[0]",
   "id": "65488103fb93351e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([97191,   369,   264,  9990, 15235, 15754,  7128, 17601, 44196,   537,\n",
       "         1172,   697, 10916,  7361,   714,  1083,   697,  3139,   304,  6388,\n",
       "         7079,   323,  7263,    11,   438,  1632,   438,   697,  5726,   311,\n",
       "        19032,  6351,  6708,  9355,    13,  5692,   748,   264, 32930,  5486,\n",
       "          311,  1492,   498, 10549,  1447, 14374,   220,    16,    13, 26668,\n",
       "        31925,   198,    12,  3070, 33464, 20909, 23752,    82, 95518,  2823,\n",
       "        68265,   448,  5411, 48025,  1075, 94986,    11,  5355,    51, 21584,\n",
       "           11,   730,  9247,    11,  4992,   624,    12,  3070, 21605, 20909,\n",
       "        85759, 95518, 70894,   323,   387,  2952,   311,  4211,  5257, 25185,\n",
       "         1741,   438,  5480, 12408,    11, 90009,    82,    11, 29728, 14155,\n",
       "           11,  4992,   624,    12,  3070, 54281, 11434, 28125,   320,    45,\n",
       "        12567, 32295,    25, 33601,  9538,   487,   448,   451, 12567, 12538,\n",
       "          323,  7375,   374, 16587,   624,    12,  3070, 37332, 30441, 95518,\n",
       "        31925,   315,  2168,  8692,   323,  6366, 11129, 12538,   624,    12,\n",
       "         3070,   693,   258, 10927, 20909, 95518, 45451,   315, 71278,  6832,\n",
       "        18940,   323,  8357,   624,    12,  3070, 13859, 16595, 95518, 64944,\n",
       "          369,  6825, 22414,  4419,   504,  7112,   821,   624,    12,  3070,\n",
       "         1712, 39288, 54190, 95518, 33601,  9538,   487,   448, 16734,  1075,\n",
       "        13403,    11, 16052,    11, 19091,    11,   434,    16,  5456,    11,\n",
       "        97826,  6691,  5459,    11,  4992,   382, 14374,   220,    17,    13,\n",
       "         5787, 20796,   198,    12,  3070,  4207, 18720, 95518, 31166, 11682,\n",
       "         1142,  7822,   315,  7079,   498,   614,  6439,   389,    13, 55994,\n",
       "          279,  3491,  5114,    11,   697,  3476,    11,   279, 14310,  1483,\n",
       "           11,   279, 11513, 16601,    11,   323,   279, 19554,   624,    12,\n",
       "         3070, 71503, 95518, 65279,   279,  5421,   315,   697,   975,   389,\n",
       "          279,  2562,   476,   279,  2390,   382, 14374,   220,    18,    13,\n",
       "        36163,   323,  7909,  9551,   198,    12,  3070,  7849,  9551, 95518,\n",
       "        20796,   304, 18150, 15235,  7079,   504, 42556,   311, 23172,   624,\n",
       "           12,  3070, 14597, 86587, 95518, 35983,   311,  2990,   323, 61325,\n",
       "          264,  2083,   624,    12,  3070, 65411, 30240, 95518, 13449,  3132,\n",
       "        19032, 10916, 18940,   311,  2477,    12, 72137, 38110,   382, 14374,\n",
       "          220,    19,    13, 22079,  6222, 19648, 30240,   198,    12,  3070,\n",
       "        27847,  6982, 95518,  2823,  5527,   311,  2884,   323, 29436, 25185,\n",
       "          624,    12,  3070,  7939,  3173, 95518, 20796,   304, 27703,  6351,\n",
       "         4119,   323,  5942,   624,    12,  3070, 21367, 65964, 95518, 64944,\n",
       "          369, 73042,  1614,  5068,   323, 15024,   382, 14374,   220,    20,\n",
       "           13, 24079, 30240,   198,    12,  3070, 31198, 11473,  4405, 95518,\n",
       "        32305, 69915,   697,  5726,   311, 11625,  5322, 92296,   624,    12,\n",
       "         3070,  2589,  2689,  2897, 95518,  6928,  1246,   498, 10515,   311,\n",
       "          501, 14310,   323, 10018,  8502,   624,    12,  3070, 69329,   311,\n",
       "        25771, 95518, 55994,   697,  6529,   311,  7716,   304,   697,   975,\n",
       "          382, 14374,   220,    21,    13, 31467, 73335,   198,    12,  3070,\n",
       "        88492, 23382, 95518, 31166, 11253,   311,  4185,  7128,  4755,    13,\n",
       "         5692,   525,  1045, 10295,   510,   220,   481,  3070, 62226, 23382,\n",
       "          334,   510,   262,   481, 81917,   264,  3151,  5662,  6832, 12111,\n",
       "          498,  3982, 11537,   624,   262,   481,  2585,   653,   498,  3705,\n",
       "          916,  6276,  1280,   304,   264,  5538,  6832,  1614,  5267,   262,\n",
       "          481, 60785,   264,  2390,  1380,   498,  1483,   451, 12567,   624,\n",
       "          220,   481,  3070, 22753,   278, 23382,   334,   510,   262,   481,\n",
       "        24647,   752,   911,   264,   882,   979,   498,  1030,   311,  3484,\n",
       "          448,   264,  5000, 18279,  4251,   624,   262,   481, 60785,   264,\n",
       "         2390,  1380], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T04:44:43.941630Z",
     "start_time": "2025-10-13T04:44:43.935226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "generated_ids"
   ],
   "id": "bcdbc2d888f0d44",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([97191,   369,   264,  9990, 15235, 15754,  7128, 17601, 44196,   537,\n",
       "          1172,   697, 10916,  7361,   714,  1083,   697,  3139,   304,  6388,\n",
       "          7079,   323,  7263,    11,   438,  1632,   438,   697,  5726,   311,\n",
       "         19032,  6351,  6708,  9355,    13,  5692,   748,   264, 32930,  5486,\n",
       "           311,  1492,   498, 10549,  1447, 14374,   220,    16,    13, 26668,\n",
       "         31925,   198,    12,  3070, 33464, 20909, 23752,    82, 95518,  2823,\n",
       "         68265,   448,  5411, 48025,  1075, 94986,    11,  5355,    51, 21584,\n",
       "            11,   730,  9247,    11,  4992,   624,    12,  3070, 21605, 20909,\n",
       "         85759, 95518, 70894,   323,   387,  2952,   311,  4211,  5257, 25185,\n",
       "          1741,   438,  5480, 12408,    11, 90009,    82,    11, 29728, 14155,\n",
       "            11,  4992,   624,    12,  3070, 54281, 11434, 28125,   320,    45,\n",
       "         12567, 32295,    25, 33601,  9538,   487,   448,   451, 12567, 12538,\n",
       "           323,  7375,   374, 16587,   624,    12,  3070, 37332, 30441, 95518,\n",
       "         31925,   315,  2168,  8692,   323,  6366, 11129, 12538,   624,    12,\n",
       "          3070,   693,   258, 10927, 20909, 95518, 45451,   315, 71278,  6832,\n",
       "         18940,   323,  8357,   624,    12,  3070, 13859, 16595, 95518, 64944,\n",
       "           369,  6825, 22414,  4419,   504,  7112,   821,   624,    12,  3070,\n",
       "          1712, 39288, 54190, 95518, 33601,  9538,   487,   448, 16734,  1075,\n",
       "         13403,    11, 16052,    11, 19091,    11,   434,    16,  5456,    11,\n",
       "         97826,  6691,  5459,    11,  4992,   382, 14374,   220,    17,    13,\n",
       "          5787, 20796,   198,    12,  3070,  4207, 18720, 95518, 31166, 11682,\n",
       "          1142,  7822,   315,  7079,   498,   614,  6439,   389,    13, 55994,\n",
       "           279,  3491,  5114,    11,   697,  3476,    11,   279, 14310,  1483,\n",
       "            11,   279, 11513, 16601,    11,   323,   279, 19554,   624,    12,\n",
       "          3070, 71503, 95518, 65279,   279,  5421,   315,   697,   975,   389,\n",
       "           279,  2562,   476,   279,  2390,   382, 14374,   220,    18,    13,\n",
       "         36163,   323,  7909,  9551,   198,    12,  3070,  7849,  9551, 95518,\n",
       "         20796,   304, 18150, 15235,  7079,   504, 42556,   311, 23172,   624,\n",
       "            12,  3070, 14597, 86587, 95518, 35983,   311,  2990,   323, 61325,\n",
       "           264,  2083,   624,    12,  3070, 65411, 30240, 95518, 13449,  3132,\n",
       "         19032, 10916, 18940,   311,  2477,    12, 72137, 38110,   382, 14374,\n",
       "           220,    19,    13, 22079,  6222, 19648, 30240,   198,    12,  3070,\n",
       "         27847,  6982, 95518,  2823,  5527,   311,  2884,   323, 29436, 25185,\n",
       "           624,    12,  3070,  7939,  3173, 95518, 20796,   304, 27703,  6351,\n",
       "          4119,   323,  5942,   624,    12,  3070, 21367, 65964, 95518, 64944,\n",
       "           369, 73042,  1614,  5068,   323, 15024,   382, 14374,   220,    20,\n",
       "            13, 24079, 30240,   198,    12,  3070, 31198, 11473,  4405, 95518,\n",
       "         32305, 69915,   697,  5726,   311, 11625,  5322, 92296,   624,    12,\n",
       "          3070,  2589,  2689,  2897, 95518,  6928,  1246,   498, 10515,   311,\n",
       "           501, 14310,   323, 10018,  8502,   624,    12,  3070, 69329,   311,\n",
       "         25771, 95518, 55994,   697,  6529,   311,  7716,   304,   697,   975,\n",
       "           382, 14374,   220,    21,    13, 31467, 73335,   198,    12,  3070,\n",
       "         88492, 23382, 95518, 31166, 11253,   311,  4185,  7128,  4755,    13,\n",
       "          5692,   525,  1045, 10295,   510,   220,   481,  3070, 62226, 23382,\n",
       "           334,   510,   262,   481, 81917,   264,  3151,  5662,  6832, 12111,\n",
       "           498,  3982, 11537,   624,   262,   481,  2585,   653,   498,  3705,\n",
       "           916,  6276,  1280,   304,   264,  5538,  6832,  1614,  5267,   262,\n",
       "           481, 60785,   264,  2390,  1380,   498,  1483,   451, 12567,   624,\n",
       "           220,   481,  3070, 22753,   278, 23382,   334,   510,   262,   481,\n",
       "         24647,   752,   911,   264,   882,   979,   498,  1030,   311,  3484,\n",
       "           448,   264,  5000, 18279,  4251,   624,   262,   481, 60785,   264,\n",
       "          2390,  1380], device='cuda:0')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T04:44:53.338012Z",
     "start_time": "2025-10-13T04:44:53.335606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(response)"
   ],
   "id": "fa5ae8a4a6c36cac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing for a senior AI developer interview involves demonstrating not only your technical skills but also your experience in leading projects and teams, as well as your ability to communicate complex ideas clearly. Here’s a structured approach to help you prepare:\n",
      "\n",
      "### 1. Technical Knowledge\n",
      "- **Deep Learning Frameworks**: Be proficient with popular frameworks like TensorFlow, PyTorch, Keras, etc.\n",
      "- **Machine Learning Algorithms**: Understand and be able to implement various algorithms such as decision trees, SVMs, neural networks, etc.\n",
      "- **Natural Language Processing (NLP)**: Familiarity with NLP techniques and tools is crucial.\n",
      "- **Computer Vision**: Knowledge of image processing and computer vision techniques.\n",
      "- **Reinforcement Learning**: Understanding of reinforcement learning concepts and applications.\n",
      "- **Feature Engineering**: Techniques for creating meaningful features from raw data.\n",
      "- **Model Evaluation Metrics**: Familiarity with metrics like accuracy, precision, recall, F1 score, ROC-AUC, etc.\n",
      "\n",
      "### 2. Project Experience\n",
      "- **Case Studies**: Prepare detailed case studies of projects you have worked on. Highlight the problem statement, your role, the technologies used, the challenges faced, and the outcomes.\n",
      "- **Impact**: Discuss the impact of your work on the business or the project.\n",
      "\n",
      "### 3. Leadership and Team Management\n",
      "- **Project Management**: Experience in managing AI projects from conception to deployment.\n",
      "- **Team Collaboration**: Ability to lead and motivate a team.\n",
      "- **Communication Skills**: Effectively communicate technical concepts to non-technical stakeholders.\n",
      "\n",
      "### 4. Problem-Solving Skills\n",
      "- **Algorithm Design**: Be ready to design and optimize algorithms.\n",
      "- **Debugging**: Experience in debugging complex models and systems.\n",
      "- **Optimization**: Techniques for optimizing model performance and efficiency.\n",
      "\n",
      "### 5. Soft Skills\n",
      "- **Problem Solving**: Demonstrate your ability to solve problems creatively.\n",
      "- **Adaptability**: Show how you adapt to new technologies and changing requirements.\n",
      "- **Attention to Detail**: Highlight your attention to detail in your work.\n",
      "\n",
      "### 6. Interview Preparation\n",
      "- **Practice Questions**: Prepare answers to common interview questions. Here are some examples:\n",
      "  - **Technical Questions**:\n",
      "    - Explain a specific machine learning algorithm you’ve implemented.\n",
      "    - How do you handle overfitting in a deep learning model?\n",
      "    - Describe a project where you used NLP.\n",
      "  - **Behavioral Questions**:\n",
      "    - Tell me about a time when you had to deal with a difficult stakeholder.\n",
      "    - Describe a project where\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c73d49aed7607fe8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a4f75289b5b50eef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Metrics"
   ],
   "id": "3608cdb041f9b4d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T05:15:16.804087Z",
     "start_time": "2025-10-13T05:14:59.718128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Any\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from threading import Thread\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList, TextIteratorStreamer\n",
    "\n",
    "class TokenTimingCriteria(StoppingCriteria):\n",
    "    \"\"\"Records a timestamp at each decoding step (one per generated token).\"\"\"\n",
    "    def __init__(self, device_type=\"cpu\", sync_each_step=True):\n",
    "        super().__init__()\n",
    "        self.timestamps = []\n",
    "        self.device_type = device_type\n",
    "        self.sync_each_step = sync_each_step\n",
    "\n",
    "    def _now(self):\n",
    "        # Ensure GPU kernels are finished before timing (accurate per-token)\n",
    "        if self.device_type.startswith(\"cuda\") and self.sync_each_step:\n",
    "            torch.cuda.synchronize()\n",
    "        return time.perf_counter()\n",
    "\n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        self.timestamps.append(self._now())\n",
    "        return False  # never stop on our own\n",
    "\n",
    "\n",
    "def generate_with_streaming(model, tokenizer, model_inputs, max_new_tokens=128, print_stream=True):\n",
    "    # Resolve device type robustly\n",
    "    device_type = model.device.type\n",
    "\n",
    "    # Stopping criteria for accurate per-token timing\n",
    "    timer = TokenTimingCriteria(device_type=device_type, sync_each_step=True)\n",
    "    stopping = StoppingCriteriaList([timer])\n",
    "\n",
    "    # Text streamer for user-visible incremental text\n",
    "    streamer = TextIteratorStreamer(\n",
    "        tokenizer,\n",
    "        skip_special_tokens=True,\n",
    "        skip_prompt=True\n",
    "    )\n",
    "\n",
    "    # Kick off generation in a background thread\n",
    "    gen_kwargs = dict(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.8,\n",
    "        stopping_criteria=stopping,\n",
    "        streamer=streamer,\n",
    "    )\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    thread = Thread(target=model.generate, kwargs=gen_kwargs, daemon=True)\n",
    "    thread.start()\n",
    "\n",
    "    # Consume stream while generation runs (prints as it arrives)\n",
    "    pieces = []\n",
    "    for chunk in streamer:\n",
    "        if print_stream:\n",
    "            print(chunk, end=\"\", flush=True)\n",
    "        pieces.append(chunk)\n",
    "\n",
    "    thread.join()\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    # Build metrics from true per-token timestamps\n",
    "    metrics = get_metrics(end_time, start_time, timer)\n",
    "\n",
    "    return \"\".join(pieces), metrics\n",
    "\n",
    "\n",
    "def get_metrics(end_time: float, start_time: float, timer: TokenTimingCriteria) -> dict[Any, Any]:\n",
    "    ts = np.asarray(timer.timestamps, dtype=np.float64)\n",
    "    metrics = {}\n",
    "\n",
    "    if ts.size >= 1:\n",
    "        ttft_ms = (ts[0] - start_time) * 1000.0\n",
    "        metrics[\"ttft_ms\"] = float(ttft_ms)\n",
    "        metrics[\"num_generated_tokens\"] = int(ts.size)\n",
    "        metrics[\"total_time_s\"] = float(end_time - start_time)\n",
    "        metrics[\"throughput_tokens_per_sec\"] = float(\n",
    "            (ts.size / (end_time - start_time)) if end_time > start_time else 0.0\n",
    "        )\n",
    "\n",
    "        if ts.size >= 2:\n",
    "            inter_ms = np.diff(ts) * 1000.0\n",
    "            metrics[\"tpot_mean_ms\"] = float(np.mean(inter_ms))\n",
    "            metrics[\"tpot_p50_ms\"] = float(np.percentile(inter_ms, 50))\n",
    "            metrics[\"tpot_p95_ms\"] = float(np.percentile(inter_ms, 95))\n",
    "    else:\n",
    "        # No tokens generated\n",
    "        metrics = {\n",
    "            \"ttft_ms\": None,\n",
    "            \"num_generated_tokens\": 0,\n",
    "            \"total_time_s\": float(end_time - start_time),\n",
    "            \"throughput_tokens_per_sec\": 0.0,\n",
    "        }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# ===== Example usage =====\n",
    "generated_text, metrics = generate_with_streaming(model, tokenizer, model_inputs, max_new_tokens=1024, print_stream=True)\n",
    "print(\"\\n\", \"=\"*20, \"METRICS\", \"=\"*20)\n",
    "for key, value in metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n"
   ],
   "id": "571624cb2bb5a67b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Preparing for a senior AI developer interview involves not only technical knowledge but also practical experience and the ability to communicate your ideas effectively. Here’s a structured approach to help you prepare:\n",
      "\n",
      "### 1. Review Core Concepts\n",
      "- **Machine Learning**: Understand key concepts like supervised, unsupervised, and reinforcement learning.\n",
      "- **Deep Learning**: Be familiar with neural networks, convolutional neural networks (CNNs), recurrent neural networks (RNNs), and transformers.\n",
      "- **Natural Language Processing (NLP)**: Know about text preprocessing, word embeddings, sequence models, and sentiment analysis.\n",
      "- **Computer Vision**: Understand image processing, object detection, segmentation, and deep learning techniques in computer vision.\n",
      "\n",
      "### 2. Practical Experience\n",
      "- **Projects**: Have a few significant projects to discuss. Prepare to explain:\n",
      "  - The problem you solved\n",
      "  - The technology stack used\n",
      "  - Data preprocessing steps\n",
      "  - Model selection and training process\n",
      "  - Evaluation metrics and results\n",
      "  - Challenges faced and how you overcame them\n",
      "\n",
      "- **Tools and Libraries**: Be proficient in tools and libraries such as TensorFlow, PyTorch, scikit-learn, Keras, and others relevant to your field.\n",
      "\n",
      "### 3. Technical Skills\n",
      "- **Programming Languages**: Be comfortable with Python, and if applicable, other languages like C++ or Java.\n",
      "- **Data Structures and Algorithms**: Refresh your knowledge of data structures (arrays, linked lists, trees, graphs) and algorithms (searching, sorting, dynamic programming).\n",
      "- **Mathematics**: Brush up on linear algebra, calculus, probability, and statistics, which are crucial for understanding machine learning algorithms.\n",
      "\n",
      "### 4. Soft Skills\n",
      "- **Problem Solving**: Be ready to solve coding problems during the interview. Practice common algorithmic challenges and data structure problems.\n",
      "- **Communication**: Be able to explain complex technical concepts in simple terms. Practice articulating your thought process and decision-making.\n",
      "- **Collaboration**: Discuss how you work with teams, manage projects, and handle deadlines.\n",
      "\n",
      "### 5. Industry Knowledge\n",
      "- **Current Trends**: Stay updated with the latest trends in AI, such as generative AI, AI ethics, and responsible AI practices.\n",
      "- **Company Research**: Learn about the company you're interviewing with. Understand their products, services, and culture.\n",
      "\n",
      "### 6. Behavioral Questions\n",
      "- **Past Experiences**: Prepare stories that demonstrate your problem-solving skills, teamwork, and leadership abilities.\n",
      "- **Challenges**: Be ready to talk about challenging situations you’ve faced and how you resolved them.\n",
      "\n",
      "### 7. Practice Interviews\n",
      "- **Mock Interviews**: Use platforms like LeetCode, HackerRank, or interview preparation sites to practice coding questions.\n",
      "- **Peer Reviews**: Conduct mock interviews with peers or mentors who can provide feedback.\n",
      "\n",
      "### Sample Interview Questions\n",
      "Here are some sample questions you might encounter:\n",
      "\n",
      "1. **Technical Questions**:\n",
      "   - Explain the difference between supervised and unsupervised learning.\n",
      "   - What is backpropagation? How does it work?\n",
      "   - Can you explain the concept of a convolutional layer in CNNs?\n",
      "\n",
      "2. **Project-Based Questions**:\n",
      "   - Describe a project you worked on where you applied machine learning. What was the goal, and what was the outcome?\n",
      "   - How did you handle missing data in your last project?\n",
      "\n",
      "3. **Behavioral Questions**:\n",
      "   - Tell me about a time when you had to learn a new technology quickly.\n",
      "   - Describe a situation where you had to lead a team through a challenging project.\n",
      "\n",
      "4. **Industry Questions**:\n",
      "   - What do you think are the biggest ethical concerns in AI today?\n",
      "   - How do you ensure that your models are fair and unbiased?\n",
      "\n",
      "By thoroughly preparing these areas, you'll be well-equipped to handle most senior AI developer interviews. Good luck!\n",
      " ==================== METRICS ====================\n",
      "ttft_ms: 43.24\n",
      "num_generated_tokens: 778\n",
      "total_time_s: 17.08\n",
      "throughput_tokens_per_sec: 45.55\n",
      "tpot_mean_ms: 21.93\n",
      "tpot_p50_ms: 21.94\n",
      "tpot_p95_ms: 22.31\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "29216865403dd2bd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
