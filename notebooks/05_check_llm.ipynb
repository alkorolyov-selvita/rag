{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-15T05:22:40.187222Z",
     "start_time": "2025-10-15T05:22:40.185180Z"
    }
   },
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T05:22:40.231008Z",
     "start_time": "2025-10-15T05:22:40.229347Z"
    }
   },
   "cell_type": "code",
   "source": "torch.__version__",
   "id": "4d105e582e1ba041",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0+cu128'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T05:22:40.274775Z",
     "start_time": "2025-10-15T05:22:40.272907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "id": "dcfe77324190d019",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T05:22:44.477359Z",
     "start_time": "2025-10-15T05:22:40.315861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.to(device)"
   ],
   "id": "1c2aff410d03d37b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.13it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.03 GiB. GPU 0 has a total capacity of 31.37 GiB of which 185.44 MiB is free. Process 382874 has 17.11 GiB memory in use. Including non-PyTorch memory, this process has 14.06 GiB memory in use. Of the allocated memory 13.49 GiB is allocated by PyTorch, and 85.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mOutOfMemoryError\u001B[39m                          Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      3\u001B[39m model_name = \u001B[33m\"\u001B[39m\u001B[33mQwen/Qwen2.5-7B-Instruct\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m      5\u001B[39m model = AutoModelForCausalLM.from_pretrained(model_name)\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/projects/rag/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4459\u001B[39m, in \u001B[36mPreTrainedModel.to\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   4454\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m dtype_present_in_args:\n\u001B[32m   4455\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   4456\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   4457\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33m `dtype` by passing the correct `dtype` argument.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   4458\u001B[39m         )\n\u001B[32m-> \u001B[39m\u001B[32m4459\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/projects/rag/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1369\u001B[39m, in \u001B[36mModule.to\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1366\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1367\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1369\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/projects/rag/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:928\u001B[39m, in \u001B[36mModule._apply\u001B[39m\u001B[34m(self, fn, recurse)\u001B[39m\n\u001B[32m    926\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[32m    927\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.children():\n\u001B[32m--> \u001B[39m\u001B[32m928\u001B[39m         \u001B[43mmodule\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    930\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[32m    931\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[32m    932\u001B[39m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[32m    933\u001B[39m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    938\u001B[39m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[32m    939\u001B[39m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/projects/rag/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:928\u001B[39m, in \u001B[36mModule._apply\u001B[39m\u001B[34m(self, fn, recurse)\u001B[39m\n\u001B[32m    926\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[32m    927\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.children():\n\u001B[32m--> \u001B[39m\u001B[32m928\u001B[39m         \u001B[43mmodule\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    930\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[32m    931\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[32m    932\u001B[39m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[32m    933\u001B[39m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    938\u001B[39m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[32m    939\u001B[39m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/projects/rag/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:955\u001B[39m, in \u001B[36mModule._apply\u001B[39m\u001B[34m(self, fn, recurse)\u001B[39m\n\u001B[32m    951\u001B[39m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[32m    952\u001B[39m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[32m    953\u001B[39m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[32m    954\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m--> \u001B[39m\u001B[32m955\u001B[39m     param_applied = \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    956\u001B[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001B[32m    958\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_subclasses\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfake_tensor\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FakeTensor\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/projects/rag/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1355\u001B[39m, in \u001B[36mModule.to.<locals>.convert\u001B[39m\u001B[34m(t)\u001B[39m\n\u001B[32m   1348\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t.dim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[32m4\u001B[39m, \u001B[32m5\u001B[39m):\n\u001B[32m   1349\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m t.to(\n\u001B[32m   1350\u001B[39m             device,\n\u001B[32m   1351\u001B[39m             dtype \u001B[38;5;28;01mif\u001B[39;00m t.is_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t.is_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1352\u001B[39m             non_blocking,\n\u001B[32m   1353\u001B[39m             memory_format=convert_to_format,\n\u001B[32m   1354\u001B[39m         )\n\u001B[32m-> \u001B[39m\u001B[32m1355\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1356\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1357\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1358\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1359\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1360\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m   1361\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e) == \u001B[33m\"\u001B[39m\u001B[33mCannot copy out of meta tensor; no data!\u001B[39m\u001B[33m\"\u001B[39m:\n",
      "\u001B[31mOutOfMemoryError\u001B[39m: CUDA out of memory. Tried to allocate 2.03 GiB. GPU 0 has a total capacity of 31.37 GiB of which 185.44 MiB is free. Process 382874 has 17.11 GiB memory in use. Including non-PyTorch memory, this process has 14.06 GiB memory in use. Of the allocated memory 13.49 GiB is allocated by PyTorch, and 85.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T05:22:44.478936701Z",
     "start_time": "2025-10-13T05:18:15.310137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer"
   ],
   "id": "ec9084bcc23eb8b8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T05:22:44.479226224Z",
     "start_time": "2025-10-13T05:18:15.722515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"Help me prepare for my Senior AI developer interview\"\n",
    "\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    conversation,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "\n",
    "text"
   ],
   "id": "7dd82eb2ff319e13",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nHelp me prepare for my Senior AI developer interview<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T05:22:44.479419836Z",
     "start_time": "2025-10-13T05:18:15.766397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "model_inputs"
   ],
   "id": "5f4784084cfa5cb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151644,   8948,    198,   2610,    525,   1207,  16948,     11,   3465,\n",
       "            553,  54364,  14817,     13,   1446,    525,    264,  10950,  17847,\n",
       "             13, 151645,    198, 151644,    872,    198,  12689,    752,  10549,\n",
       "            369,    847,  19342,  15235,  15754,   7128, 151645,    198, 151644,\n",
       "          77091,    198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T05:22:44.479567498Z",
     "start_time": "2025-10-13T05:18:15.810367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tic = time.time()\n",
    "generated_ids = model.generate(**model_inputs, max_new_tokens=512)\n",
    "toc = time.time()\n",
    "\n"
   ],
   "id": "aa475e478f676b2a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T05:22:44.479724729Z",
     "start_time": "2025-10-13T05:18:27.071025Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "80cd9bbb1dc50de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T05:22:44.479847981Z",
     "start_time": "2025-10-13T05:18:27.113163Z"
    }
   },
   "cell_type": "code",
   "source": "model_inputs.input_ids",
   "id": "51f4f78991141ad1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[151644,   8948,    198,   2610,    525,   1207,  16948,     11,   3465,\n",
       "            553,  54364,  14817,     13,   1446,    525,    264,  10950,  17847,\n",
       "             13, 151645,    198, 151644,    872,    198,  12689,    752,  10549,\n",
       "            369,    847,  19342,  15235,  15754,   7128, 151645,    198, 151644,\n",
       "          77091,    198]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T05:22:44.479995742Z",
     "start_time": "2025-10-13T05:18:27.155289Z"
    }
   },
   "cell_type": "code",
   "source": "generated_ids[0]",
   "id": "65488103fb93351e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([151644,   8948,    198,   2610,    525,   1207,  16948,     11,   3465,\n",
       "           553,  54364,  14817,     13,   1446,    525,    264,  10950,  17847,\n",
       "            13, 151645,    198, 151644,    872,    198,  12689,    752,  10549,\n",
       "           369,    847,  19342,  15235,  15754,   7128, 151645,    198, 151644,\n",
       "         77091,    198,  97191,    369,    264,   9990,  15235,  15754,   7128,\n",
       "         17601,   8660,   2176,    279,  10916,  13566,    315,  15235,    323,\n",
       "           279,  26829,   2266,    304,    892,   1493,  14310,    525,   9251,\n",
       "            13,   5692,    748,    264,  32930,   5486,    311,   1492,    498,\n",
       "         10549,   1447,  14374,    220,     16,     13,  26668,  31925,    271,\n",
       "           820,   9518,  75772,    510,     12,   3070,  21605,  20909,  95518,\n",
       "         70894,   5257,  19614,  25185,    320,     68,   1302,   2572,  13482,\n",
       "         30549,     11,   5480,  12408,     11,  90009,     82,     11,  29728,\n",
       "         14155,    701,    862,  35386,     11,  43567,     11,    323,    979,\n",
       "           311,    990,   1105,    624,     12,   3070,  33464,  20909,  95518,\n",
       "          2823,  11285,    448,   5538,   6832,  77235,   1075,  19769,     82,\n",
       "            11,    431,   9745,     82,     11,    444,    784,  21634,     11,\n",
       "           323,  86870,    624,     12,   3070,  54281,  11434,  28125,    320,\n",
       "            45,  12567,  32295,     25,  31925,    315,    451,  12567,  12538,\n",
       "            11,   4119,    320,  61437,     11,    479,   2828,    701,    323,\n",
       "          8357,    624,     12,   3070,  37332,  30441,  95518,  45451,    315,\n",
       "          2168,   8692,     11,   1633,  17984,     11,  59752,     11,    323,\n",
       "          3579,  17843,    382,    820,  23752,     82,    323,  13852,    510,\n",
       "            12,   3070,  25336,  18878,    334,    323,   3070,  13828,     51,\n",
       "         21584,  95518,   8459,  10387,    304,   1667,   1493,  48025,    369,\n",
       "          4752,    323,   4862,   4119,    624,     12,   3070,   3326,  60403,\n",
       "          8125,  10118,  95518,  50512,    369,   6770,   5662,   6832,   9079,\n",
       "           624,     12,   3070,     42,   9247,  95518,    362,   1550,  11591,\n",
       "          5333,    369,  94986,    624,     12,   3070,   5002,  19589,  95518,\n",
       "          1752,   6366,  11129,   9079,    624,     12,   3070,  30042,  15778,\n",
       "           334,    323,   3070,  89198,  56715,  95518,   1752,    451,  12567,\n",
       "          9079,    382,    820,  39288,  54190,    510,     12,   3070,  45822,\n",
       "         97219,   3070,  55501,  97219,   3070,   3820,    541,  97219,   3070,\n",
       "            37,     16,  18115,   1019,     12,   3070,  73645,  35933,  97219,\n",
       "          3070,     32,   5459,   1019,     12,   3070,  28501,  58346,  56177,\n",
       "           820,  57739,  64944,    510,     12,   3070,  29369,   3874,   1168,\n",
       "          1019,     12,   3070,  30404,   2022,    334,    320,     43,     16,\n",
       "            11,    444,     17,    340,     12,   3070,  21074,  18437,   2022,\n",
       "          1019,     12,   3070,  19871,    411,  56177,    820,  66292,    323,\n",
       "         24039,    510,     12,   3070,   1712,  71643,  95518,  45451,   1246,\n",
       "           311,  10517,   4119,    304,   5670,    624,     12,   3070,   7082,\n",
       "         40069,  95518,   2585,    311,  31072,   4119,   1119,   3482,    476,\n",
       "          6371,   8357,    624,     12,   3070,  11237,     14,   6484,  77382,\n",
       "         10999,  95518,  68967,  17590,    323,  23172,  11364,    382,  14374,\n",
       "           220,     17,     13,  22079,   6222,  19648,  30240,    271,    820,\n",
       "         11538,  18720,    510,     12,  31166,    311,   4263,   3267,   7079,\n",
       "          1380,    498,    614,   9251,  15235,   9904,    624,     12,  65279,\n",
       "         11513,  16601,    323,   1246,    498,    916,   6014,   1105,    382,\n",
       "           820,  40325,   6982,    510,     12,   2823,   5527,    311,   2884,\n",
       "           323,  10339,  25185,    369,   3151,   5322,    624,     12,  65279,\n",
       "          6559,  63939,   1948,   2155,  19827,    382,  14374,    220,     18,\n",
       "            13,  24079,  30240,    271,    820,  30866,    510,     12,  81917,\n",
       "          6351,  10916,  18940,    304,   4285,   3793,    624,     12,  35983,\n",
       "           311,  10339,    697,   3381,   1882,   2337,   3491,  98146,    382,\n",
       "           820,   7909,  86587,    510,     12,  65279,  11449,   3238,    304,\n",
       "          5312,  98516,   7263,    624,     12,  25311,    315,  11438,    323,\n",
       "         75479,    382,    820,   4120,   9551,    510,     12,  60785,   1246,\n",
       "           498,  10091,    882,    323,  62552,   9079,    304,    264,   4937,\n",
       "         64219,   4573,    382,  14374,    220,     19,     13,  71984,  23382,\n",
       "           271,    820,  36163,    510,     12,  60785,    264,   6534,   1380,\n",
       "           498,   1030,    311,   2990,    264,   2083,    624,     12,   2585,\n",
       "           653,    498,   3705,  25800,   2878,    264,   2083,   1939,    820,\n",
       "         58431], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T05:22:44.480156534Z",
     "start_time": "2025-10-13T05:18:27.197145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "generated_ids"
   ],
   "id": "bcdbc2d888f0d44",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([97191,   369,   264,  9990, 15235, 15754,  7128, 17601,  8660,  2176,\n",
       "           279, 10916, 13566,   315, 15235,   323,   279, 26829,  2266,   304,\n",
       "           892,  1493, 14310,   525,  9251,    13,  5692,   748,   264, 32930,\n",
       "          5486,   311,  1492,   498, 10549,  1447, 14374,   220,    16,    13,\n",
       "         26668, 31925,   271,   820,  9518, 75772,   510,    12,  3070, 21605,\n",
       "         20909, 95518, 70894,  5257, 19614, 25185,   320,    68,  1302,  2572,\n",
       "         13482, 30549,    11,  5480, 12408,    11, 90009,    82,    11, 29728,\n",
       "         14155,   701,   862, 35386,    11, 43567,    11,   323,   979,   311,\n",
       "           990,  1105,   624,    12,  3070, 33464, 20909, 95518,  2823, 11285,\n",
       "           448,  5538,  6832, 77235,  1075, 19769,    82,    11,   431,  9745,\n",
       "            82,    11,   444,   784, 21634,    11,   323, 86870,   624,    12,\n",
       "          3070, 54281, 11434, 28125,   320,    45, 12567, 32295,    25, 31925,\n",
       "           315,   451, 12567, 12538,    11,  4119,   320, 61437,    11,   479,\n",
       "          2828,   701,   323,  8357,   624,    12,  3070, 37332, 30441, 95518,\n",
       "         45451,   315,  2168,  8692,    11,  1633, 17984,    11, 59752,    11,\n",
       "           323,  3579, 17843,   382,   820, 23752,    82,   323, 13852,   510,\n",
       "            12,  3070, 25336, 18878,   334,   323,  3070, 13828,    51, 21584,\n",
       "         95518,  8459, 10387,   304,  1667,  1493, 48025,   369,  4752,   323,\n",
       "          4862,  4119,   624,    12,  3070,  3326, 60403,  8125, 10118, 95518,\n",
       "         50512,   369,  6770,  5662,  6832,  9079,   624,    12,  3070,    42,\n",
       "          9247, 95518,   362,  1550, 11591,  5333,   369, 94986,   624,    12,\n",
       "          3070,  5002, 19589, 95518,  1752,  6366, 11129,  9079,   624,    12,\n",
       "          3070, 30042, 15778,   334,   323,  3070, 89198, 56715, 95518,  1752,\n",
       "           451, 12567,  9079,   382,   820, 39288, 54190,   510,    12,  3070,\n",
       "         45822, 97219,  3070, 55501, 97219,  3070,  3820,   541, 97219,  3070,\n",
       "            37,    16, 18115,  1019,    12,  3070, 73645, 35933, 97219,  3070,\n",
       "            32,  5459,  1019,    12,  3070, 28501, 58346, 56177,   820, 57739,\n",
       "         64944,   510,    12,  3070, 29369,  3874,  1168,  1019,    12,  3070,\n",
       "         30404,  2022,   334,   320,    43,    16,    11,   444,    17,   340,\n",
       "            12,  3070, 21074, 18437,  2022,  1019,    12,  3070, 19871,   411,\n",
       "         56177,   820, 66292,   323, 24039,   510,    12,  3070,  1712, 71643,\n",
       "         95518, 45451,  1246,   311, 10517,  4119,   304,  5670,   624,    12,\n",
       "          3070,  7082, 40069, 95518,  2585,   311, 31072,  4119,  1119,  3482,\n",
       "           476,  6371,  8357,   624,    12,  3070, 11237,    14,  6484, 77382,\n",
       "         10999, 95518, 68967, 17590,   323, 23172, 11364,   382, 14374,   220,\n",
       "            17,    13, 22079,  6222, 19648, 30240,   271,   820, 11538, 18720,\n",
       "           510,    12, 31166,   311,  4263,  3267,  7079,  1380,   498,   614,\n",
       "          9251, 15235,  9904,   624,    12, 65279, 11513, 16601,   323,  1246,\n",
       "           498,   916,  6014,  1105,   382,   820, 40325,  6982,   510,    12,\n",
       "          2823,  5527,   311,  2884,   323, 10339, 25185,   369,  3151,  5322,\n",
       "           624,    12, 65279,  6559, 63939,  1948,  2155, 19827,   382, 14374,\n",
       "           220,    18,    13, 24079, 30240,   271,   820, 30866,   510,    12,\n",
       "         81917,  6351, 10916, 18940,   304,  4285,  3793,   624,    12, 35983,\n",
       "           311, 10339,   697,  3381,  1882,  2337,  3491, 98146,   382,   820,\n",
       "          7909, 86587,   510,    12, 65279, 11449,  3238,   304,  5312, 98516,\n",
       "          7263,   624,    12, 25311,   315, 11438,   323, 75479,   382,   820,\n",
       "          4120,  9551,   510,    12, 60785,  1246,   498, 10091,   882,   323,\n",
       "         62552,  9079,   304,   264,  4937, 64219,  4573,   382, 14374,   220,\n",
       "            19,    13, 71984, 23382,   271,   820, 36163,   510,    12, 60785,\n",
       "           264,  6534,  1380,   498,  1030,   311,  2990,   264,  2083,   624,\n",
       "            12,  2585,   653,   498,  3705, 25800,  2878,   264,  2083,  1939,\n",
       "           820, 58431], device='cuda:0')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T05:22:44.480324356Z",
     "start_time": "2025-10-13T05:18:27.241053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(response)"
   ],
   "id": "fa5ae8a4a6c36cac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing for a senior AI developer interview involves understanding both the technical aspects of AI and the broader context in which these technologies are applied. Here’s a structured approach to help you prepare:\n",
      "\n",
      "### 1. Technical Knowledge\n",
      "\n",
      "#### Core Concepts:\n",
      "- **Machine Learning**: Understand various ML algorithms (e.g., linear regression, decision trees, SVMs, neural networks), their strengths, weaknesses, and when to use them.\n",
      "- **Deep Learning**: Be familiar with deep learning architectures like CNNs, RNNs, LSTMs, and transformers.\n",
      "- **Natural Language Processing (NLP)**: Knowledge of NLP techniques, models (BERT, GPT), and applications.\n",
      "- **Computer Vision**: Understanding of image processing, object detection, segmentation, and face recognition.\n",
      "\n",
      "#### Frameworks and Tools:\n",
      "- **TensorFlow** and **PyTorch**: Proficiency in using these frameworks for building and training models.\n",
      "- **Scikit-Learn**: Useful for basic machine learning tasks.\n",
      "- **Keras**: A high-level API for TensorFlow.\n",
      "- **OpenCV**: For computer vision tasks.\n",
      "- **NLTK** and **spaCy**: For NLP tasks.\n",
      "\n",
      "#### Evaluation Metrics:\n",
      "- **Accuracy**, **Precision**, **Recall**, **F1 Score**\n",
      "- **ROC curves**, **AUC**\n",
      "- **Cross-validation**\n",
      "\n",
      "#### Optimization Techniques:\n",
      "- **Gradient Descent**\n",
      "- **Regularization** (L1, L2)\n",
      "- **Batch Normalization**\n",
      "- **Dropout**\n",
      "\n",
      "#### Deployment and Production:\n",
      "- **Model Serving**: Understanding how to deploy models in production.\n",
      "- **API Integration**: How to integrate models into web or mobile applications.\n",
      "- **CI/CD Pipelines**: Continuous integration and deployment processes.\n",
      "\n",
      "### 2. Problem-Solving Skills\n",
      "\n",
      "#### Case Studies:\n",
      "- Prepare to discuss past projects where you have applied AI solutions.\n",
      "- Discuss challenges faced and how you overcame them.\n",
      "\n",
      "#### Algorithm Design:\n",
      "- Be ready to design and explain algorithms for specific problems.\n",
      "- Discuss trade-offs between different approaches.\n",
      "\n",
      "### 3. Soft Skills\n",
      "\n",
      "#### Communication:\n",
      "- Explain complex technical concepts in simple terms.\n",
      "- Ability to explain your thought process during problem-solving.\n",
      "\n",
      "#### Team Collaboration:\n",
      "- Discuss experiences working in cross-functional teams.\n",
      "- Examples of leadership and mentoring.\n",
      "\n",
      "#### Time Management:\n",
      "- Describe how you manage time and prioritize tasks in a fast-paced environment.\n",
      "\n",
      "### 4. Behavioral Questions\n",
      "\n",
      "#### Leadership:\n",
      "- Describe a situation where you had to lead a team.\n",
      "- How do you handle conflicts within a team?\n",
      "\n",
      "#### Adapt\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T05:22:44.480444297Z",
     "start_time": "2025-10-13T05:18:27.283112Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c73d49aed7607fe8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T05:22:44.480567478Z",
     "start_time": "2025-10-13T05:18:27.325073Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a4f75289b5b50eef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Metricsь"
   ],
   "id": "3608cdb041f9b4d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T05:22:44.480701400Z",
     "start_time": "2025-10-15T04:29:19.980422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Any\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from threading import Thread\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList, TextIteratorStreamer\n",
    "\n",
    "class TokenTimingCriteria(StoppingCriteria):\n",
    "    \"\"\"Records a timestamp at each decoding step (one per generated token).\"\"\"\n",
    "    def __init__(self, device_type=\"cpu\", sync_each_step=True):\n",
    "        super().__init__()\n",
    "        self.timestamps = []\n",
    "        self.device_type = device_type\n",
    "        self.sync_each_step = sync_each_step\n",
    "\n",
    "    def _now(self):\n",
    "        # Ensure GPU kernels are finished before timing (accurate per-token)\n",
    "        if self.device_type.startswith(\"cuda\") and self.sync_each_step:\n",
    "            torch.cuda.synchronize()\n",
    "        return time.perf_counter()\n",
    "\n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        self.timestamps.append(self._now())\n",
    "        return False  # never stop on our own\n",
    "\n",
    "\n",
    "def generate_with_streaming(model, tokenizer, model_inputs, max_new_tokens=128, print_stream=True):\n",
    "    # Resolve device type robustly\n",
    "    device_type = model.device.type\n",
    "\n",
    "    # Stopping criteria for accurate per-token timing\n",
    "    timer = TokenTimingCriteria(device_type=device_type, sync_each_step=True)\n",
    "    stopping = StoppingCriteriaList([timer])\n",
    "\n",
    "    # Text streamer for user-visible incremental text\n",
    "    streamer = TextIteratorStreamer(\n",
    "        tokenizer,\n",
    "        skip_special_tokens=True,\n",
    "        skip_prompt=True\n",
    "    )\n",
    "\n",
    "    # Kick off generation in a background thread\n",
    "    gen_kwargs = dict(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.8,\n",
    "        stopping_criteria=stopping,\n",
    "        streamer=streamer,\n",
    "    )\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    thread = Thread(target=model.generate, kwargs=gen_kwargs, daemon=True)\n",
    "    thread.start()\n",
    "\n",
    "    # Consume stream while generation runs (prints as it arrives)\n",
    "    pieces = []\n",
    "    for chunk in streamer:\n",
    "        if print_stream:\n",
    "            print(chunk, end=\"\", flush=True)\n",
    "        pieces.append(chunk)\n",
    "\n",
    "    thread.join()\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    # Build metrics from true per-token timestamps\n",
    "    metrics = get_metrics(end_time, start_time, timer)\n",
    "\n",
    "    return \"\".join(pieces), metrics\n",
    "\n",
    "\n",
    "def get_metrics(end_time: float, start_time: float, timer: TokenTimingCriteria) -> dict[Any, Any]:\n",
    "    ts = np.asarray(timer.timestamps, dtype=np.float64)\n",
    "    metrics = {}\n",
    "\n",
    "    if ts.size >= 1:\n",
    "        ttft_ms = (ts[0] - start_time) * 1000.0\n",
    "        metrics[\"ttft_ms\"] = float(ttft_ms)\n",
    "        metrics[\"num_generated_tokens\"] = int(ts.size)\n",
    "        metrics[\"total_time_s\"] = float(end_time - start_time)\n",
    "        metrics[\"throughput_tokens_per_sec\"] = float(\n",
    "            (ts.size / (end_time - start_time)) if end_time > start_time else 0.0\n",
    "        )\n",
    "\n",
    "        if ts.size >= 2:\n",
    "            inter_ms = np.diff(ts) * 1000.0\n",
    "            metrics[\"tpot_mean_ms\"] = float(np.mean(inter_ms))\n",
    "            metrics[\"tpot_p50_ms\"] = float(np.percentile(inter_ms, 50))\n",
    "            metrics[\"tpot_p95_ms\"] = float(np.percentile(inter_ms, 95))\n",
    "    else:\n",
    "        # No tokens generated\n",
    "        metrics = {\n",
    "            \"ttft_ms\": None,\n",
    "            \"num_generated_tokens\": 0,\n",
    "            \"total_time_s\": float(end_time - start_time),\n",
    "            \"throughput_tokens_per_sec\": 0.0,\n",
    "        }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# ===== Example usage =====\n",
    "\n",
    "\n",
    "generated_text, metrics = generate_with_streaming(model, tokenizer, model_inputs, max_new_tokens=1024, print_stream=True)\n",
    "print(\"\\n\", \"=\"*20, \"METRICS\", \"=\"*20)\n",
    "for key, value in metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n"
   ],
   "id": "571624cb2bb5a67b",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ergot/projects/rag/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 105\u001B[39m\n\u001B[32m     99\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m metrics\n\u001B[32m    102\u001B[39m \u001B[38;5;66;03m# ===== Example usage =====\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m105\u001B[39m generated_text, metrics = generate_with_streaming(\u001B[43mmodel\u001B[49m, tokenizer, model_inputs, max_new_tokens=\u001B[32m1024\u001B[39m, print_stream=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m    106\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m=\u001B[39m\u001B[33m\"\u001B[39m*\u001B[32m20\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mMETRICS\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m=\u001B[39m\u001B[33m\"\u001B[39m*\u001B[32m20\u001B[39m)\n\u001B[32m    107\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m metrics.items():\n",
      "\u001B[31mNameError\u001B[39m: name 'model' is not defined"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T05:22:44.480855761Z",
     "start_time": "2025-10-13T05:18:44.350893Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "29216865403dd2bd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
