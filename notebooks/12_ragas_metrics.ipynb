{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-25T14:48:22.043570Z",
     "start_time": "2025-10-25T14:48:19.813361Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset\n",
    "\n",
    "from rag.pipeline import RAGPipeline\n",
    "from rag.embeddings import create_embedder\n",
    "from rag.retrieval import create_reranker\n",
    "from rag.generation import create_llm\n",
    "from rag.storage import PgvectorVectorStore, PostgresDocumentStore\n",
    "from rag.config import settings\n",
    "\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ergot/projects/rag/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:48:22 faiss.loader INFO   Loading faiss with AVX512 support.\n",
      "16:48:22 faiss.loader INFO   Successfully loaded faiss with AVX512 support.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T14:48:25.298703Z",
     "start_time": "2025-10-25T14:48:22.045757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "corpus_ds = load_dataset(\"rag-datasets/rag-mini-bioasq\", \"text-corpus\")['passages']\n",
    "queries_ds = load_dataset(\"rag-datasets/rag-mini-bioasq\", \"question-answer-passages\")['test']\n",
    "queries_ds"
   ],
   "id": "bd3db05f64a8ff1a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'relevant_passage_ids', 'id'],\n",
       "    num_rows: 4719\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T14:48:33.213969Z",
     "start_time": "2025-10-25T14:48:25.342746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "doc_store = PostgresDocumentStore(settings)\n",
    "vec_store = PgvectorVectorStore(settings)\n",
    "embedder = create_embedder(settings)\n",
    "reranker = create_reranker(settings)\n",
    "llm = create_llm(settings)\n",
    "\n",
    "rag_pipeline = RAGPipeline(\n",
    "    doc_store,\n",
    "    vec_store,\n",
    "    embedder,\n",
    "    reranker,\n",
    "    llm,\n",
    "    settings,\n",
    ")"
   ],
   "id": "ebc34df6e7c5bec9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-25 16:48:25] [rag.storage.document_stores.postgres] [INFO] PostgresDocumentStore initialized\n",
      "[2025-10-25 16:48:25] [rag.storage.document_stores.postgres] [INFO] PostgresDocumentStore initialized\n",
      "16:48:25 rag.storage.document_stores.postgres INFO   PostgresDocumentStore initialized\n",
      "[2025-10-25 16:48:25] [rag.storage.vector_stores.pgvector] [INFO] PgvectorVectorStore initialized (cosine distance)\n",
      "[2025-10-25 16:48:25] [rag.storage.vector_stores.pgvector] [INFO] PgvectorVectorStore initialized (cosine distance)\n",
      "16:48:25 rag.storage.vector_stores.pgvector INFO   PgvectorVectorStore initialized (cosine distance)\n",
      "16:48:25 sentence_transformers.SentenceTransformer INFO   Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 288.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:48:31 sentence_transformers.SentenceTransformer INFO   Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
      "16:48:33 redisvl.index.index INFO   Index already exists, not overwriting.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T14:48:33.988293Z",
     "start_time": "2025-10-25T14:48:33.259597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "  context_precision,     # Are retrieved docs relevant? (needs ground truth)\n",
    "  context_recall,        # Did we retrieve all relevant docs? (needs ground truth)\n",
    "  faithfulness,          # Is answer grounded in context? (no hallucinations)\n",
    "  answer_relevancy,      # Does answer address the question?\n",
    "  answer_correctness,    # How correct vs ground truth? (needs ground truth)\n",
    ")\n",
    "from datasets import Dataset\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load OpenAI API key for LLM-as-judge metrics\n",
    "load_dotenv()\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY not found in .env\"\n",
    "\n",
    "print(\"✓ RAGAS setup complete\")"
   ],
   "id": "46e649a4e400b66a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ RAGAS setup complete\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T14:48:34.006427Z",
     "start_time": "2025-10-25T14:48:33.990396Z"
    }
   },
   "cell_type": "code",
   "source": "# Parse relevant_passage_ids from string to list\n",
   "id": "fca6e0f1f0c8bd22",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T19:09:15.752519Z",
     "start_time": "2025-10-25T15:07:44.714503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Start with a small subset to test (5 queries)\n",
    "np.random.seed(42)\n",
    "# sample_ids = np.random.choice(len(queries_ds), size=100, replace=False)\n",
    "sample_ids = list(range(len(queries_ds)))\n",
    "\n",
    "eval_data = []\n",
    "\n",
    "def parse_relevant_ids(ids_str):\n",
    "  return ast.literal_eval(ids_str)\n",
    "\n",
    "for i in tqdm(sample_ids):\n",
    "  item = queries_ds[i]\n",
    "  question = item['question']\n",
    "  ground_truth_answer = item['answer']\n",
    "  relevant_doc_ids = parse_relevant_ids(item['relevant_passage_ids'])\n",
    "\n",
    "  # Run RAG pipeline\n",
    "  answer, chunks = rag_pipeline.query(question)\n",
    "  \n",
    "  # Deduplicate doc IDs while preserving rank order (first occurrence kept)\n",
    "  # This is critical for accurate IR metrics - duplicates would inflate precision\n",
    "  doc_ids = list(dict.fromkeys(chunk.id.split('#')[0] for chunk in chunks))\n",
    "  \n",
    "  documents = doc_store.get_documents(doc_ids)\n",
    "\n",
    "  # Extract data\n",
    "  eval_data.append({\n",
    "      'question': question,\n",
    "      'answer': answer,  # Generated answer\n",
    "      'contexts': [chunk.text for chunk in chunks],  # Retrieved texts\n",
    "      'ground_truth': ground_truth_answer,  # Gold answer\n",
    "      'retrieved_doc_ids': doc_ids,  # For analysis (deduplicated, rank-ordered)\n",
    "      'relevant_doc_ids': relevant_doc_ids,  # Gold doc IDs\n",
    "  })\n",
    "\n",
    "print(f\"\\n✓ Processed {len(sample_ids)} queries\")\n",
    "print(f\"\\nSample output:\")\n",
    "print(f\"Question: {eval_data[0]['question'][:100]}...\")\n",
    "print(f\"Answer: {eval_data[0]['answer'][:100]}...\")\n",
    "print(f\"Contexts: {len(eval_data[0]['contexts'])} documents retrieved\")"
   ],
   "id": "97a3071eb48391a2",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4719/4719 [4:01:31<00:00,  3.07s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Processed 4719 queries\n",
      "\n",
      "Sample output:\n",
      "Question: Is Hirschsprung disease a mendelian or a multifactorial disorder?...\n",
      "Answer: Hirschsprung disease (HSCR) can be both a Mendelian and a multifactorial disorder. \n",
      "\n",
      "- The non-Mende...\n",
      "Contexts: 10 documents retrieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T19:09:15.876371Z",
     "start_time": "2025-10-25T19:09:15.761016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# RAGAS expects a HuggingFace Dataset with specific columns\n",
    "ragas_data = {\n",
    "    'question': [item['question'] for item in eval_data],\n",
    "    'answer': [item['answer'] for item in eval_data],\n",
    "    'contexts': [item['contexts'] for item in eval_data],\n",
    "    'ground_truth': [item['ground_truth'] for item in eval_data],\n",
    "}\n",
    "\n",
    "ragas_dataset = Dataset.from_dict(ragas_data)\n",
    "print(\"RAGAS dataset created:\")\n",
    "print(ragas_dataset)"
   ],
   "id": "c66aab73d8aae3ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAGAS dataset created:\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'contexts', 'ground_truth'],\n",
      "    num_rows: 4719\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T19:09:15.953535Z",
     "start_time": "2025-10-25T19:09:15.878333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from rag.utils import evaluate_retrieval\n",
    "\n",
    "ir_metrics = evaluate_retrieval(eval_data, k=settings.top_k)\n",
    "ir_metrics = {k: round(v, 3) for k, v in ir_metrics.items()}\n",
    "ir_metrics"
   ],
   "id": "53a73df5dff5b9fa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P@10': 0.275,\n",
       " 'R@10': 0.342,\n",
       " 'MRR@10': 0.706,\n",
       " 'nDCG@10': 0.475,\n",
       " 'Hit@10': 0.782}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T14:51:44.660517Z",
     "start_time": "2025-10-25T14:51:44.642821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import logging\n",
    "\n",
    "# Clean output - only show errors and progress bar\n",
    "logging.getLogger(\"httpx\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"openai\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"ragas\").setLevel(logging.ERROR)\n",
    "\n",
    "# Keep your own logs visible\n",
    "logging.getLogger(\"rag\").setLevel(logging.INFO)\n",
    "\n",
    "print(\"✓ Clean logging configured\")"
   ],
   "id": "4497d34875cf4197",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Clean logging configured\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T14:51:44.712174Z",
     "start_time": "2025-10-25T14:51:44.687143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.cache import RedisCache\n",
    "from langchain.globals import set_llm_cache\n",
    "import redis\n",
    "\n",
    "# Use your existing Redis instance\n",
    "redis_client = redis.from_url(settings.redis_url, decode_responses=False)\n",
    "\n",
    "set_llm_cache(RedisCache(redis_client, ttl=settings.redis_ttl))"
   ],
   "id": "2bc60ab90860810",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T15:05:44.094466Z",
     "start_time": "2025-10-25T14:51:44.729808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from ragas.run_config import RunConfig\n",
    "from ragas import evaluate\n",
    "\n",
    "# Create async LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",  # Cheaper, faster model\n",
    "    temperature=0,\n",
    "    # max_tokens=1000,\n",
    ")\n",
    "\n",
    "# Configure parallel execution\n",
    "run_config = RunConfig(\n",
    "    max_workers=8,           # Number of parallel workers\n",
    "    timeout=120,             # Timeout per evaluation (seconds)\n",
    "    max_retries=3,           # Retry failed API calls\n",
    "    max_wait=60,             # Max wait between retries\n",
    ")\n",
    "\n",
    "\n",
    "result = evaluate(\n",
    "    dataset=ragas_dataset,\n",
    "    metrics=[\n",
    "      # context_precision,    # Are retrieved docs relevant?\n",
    "      # context_recall,       # Did we retrieve all relevant docs?\n",
    "      faithfulness,         # Is answer grounded in context?\n",
    "      answer_relevancy,     # Does answer address the question?\n",
    "      answer_correctness,   # How correct is the answer?\n",
    "    ],\n",
    "    llm=llm,\n",
    "    run_config=run_config,\n",
    ")\n",
    "\n",
    "print(\"✓ Evaluation complete!\\n\")\n",
    "print(result)"
   ],
   "id": "ea65794a28544761",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 300/300 [13:57<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Evaluation complete!\n",
      "\n",
      "{'faithfulness': 0.8169, 'answer_relevancy': 0.7953, 'answer_correctness': 0.6064}\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
