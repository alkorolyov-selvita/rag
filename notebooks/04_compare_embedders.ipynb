{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T06:54:45.341759Z",
     "start_time": "2025-10-23T06:54:39.846799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "from rag.embeddings import LocalEmbedder\n",
    "from rag.utils import embed_biorag_datasets, precision_at_k, recall_at_k, mrr_at_k, ndcg_at_k, get_hit_flags, \\\n",
    "    get_metrics\n",
    "\n",
    "doc_ds = load_dataset(\"rag-datasets/rag-mini-bioasq\", \"text-corpus\")['passages']\n",
    "query_ds = load_dataset(\"rag-datasets/rag-mini-bioasq\", \"question-answer-passages\")['test']"
   ],
   "id": "d99d192bc09230e5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ergot/projects/rag/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T06:54:45.631449Z",
     "start_time": "2025-10-23T06:54:45.344828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Precompute\n",
    "doc_id_to_text = doc_ds.select_columns(['id', 'passage']).to_pandas().set_index('id')['passage'].to_dict()\n",
    "index_to_doc_id = np.array(doc_ds['id'])\n",
    "queries = np.array(query_ds['question'])\n",
    "\n",
    "qrels = [np.array(eval(gold)) for gold in query_ds['relevant_passage_ids']]\n",
    "qrels_counts = [len(s) for s in qrels]"
   ],
   "id": "ec8ca45c6047a573",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-23T07:30:47.767882Z",
     "start_time": "2025-10-23T06:54:45.634060Z"
    }
   },
   "source": [
    "from rag.utils import embed_dataset\n",
    "# Check Different models\n",
    "import os\n",
    "import torch\n",
    "from time import time\n",
    "\n",
    "embedder_models = [\n",
    "        \"all-MiniLM-L6-v2\",\n",
    "        \"all-MiniLM-L12-v2\",\n",
    "        \"all-mpnet-base-v2\",\n",
    "        \"nomic-ai/nomic-embed-text-v1.5\",\n",
    "        \"BAAI/bge-small-en-v1.5\",\n",
    "        \"BAAI/bge-base-en-v1.5\",\n",
    "        \"BAAI/bge-large-en-v1.5\",\n",
    "        \"Alibaba-NLP/gte-multilingual-base\",\n",
    "        \"Snowflake/snowflake-arctic-embed-l-v2.0\",\n",
    "        \"jinaai/jina-embeddings-v3\",\n",
    "        \"intfloat/e5-base-v2\",\n",
    "        \"BAAI/bge-m3\",\n",
    "        \"Lajavaness/bilingual-embedding-base\",\n",
    "        \"Qwen/Qwen3-Embedding-0.6B\",\n",
    "]\n",
    "\n",
    "for i, model_name in enumerate(embedder_models):\n",
    "        print(\"=\" * 20, f\"[{i + 1}/{len(embedder_models)}]\", \"=\" * 20)\n",
    "\n",
    "        try:\n",
    "            embedder = LocalEmbedder(model_name, device=\"cuda\")\n",
    "            start_time = time()\n",
    "            doc_ds = embed_dataset(doc_ds, embedder, column=\"passage\")\n",
    "            query_ds = embed_dataset(query_ds, embedder, column=\"question\")\n",
    "            elapsed_time = time() - start_time\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to embed {model_name}: {e}\")\n",
    "            del embedder\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()b\n",
    "            continue\n",
    "\n",
    "        for faiss_metric in [\"IP\", \"L2\"]:\n",
    "            doc_ds.add_faiss_index(\n",
    "                column='embedding',\n",
    "                string_factory='Flat',\n",
    "                metric_type=faiss.METRIC_L2 if faiss_metric == 'L2' else faiss.METRIC_INNER_PRODUCT,\n",
    "                batch_size=128,\n",
    "            )\n",
    "\n",
    "            metrics = {}\n",
    "\n",
    "            for k in [1, 3, 5, 10]:\n",
    "                res = doc_ds.get_index('embedding').search_batch(np.array(query_ds['embedding']), k=k)\n",
    "                retrieved_ids = index_to_doc_id[res.total_indices]\n",
    "\n",
    "                metrics = {\n",
    "                    **metrics,\n",
    "                    **get_metrics(retrieved_ids, query_ds, k),\n",
    "                }\n",
    "\n",
    "            res_dict = {\n",
    "                'model': model_name,\n",
    "                'faiss_metric': faiss_metric,\n",
    "                'chunked': False,\n",
    "                'chunk_size': None,\n",
    "                'chunk_overlap': None,\n",
    "                'rerank_model': None,\n",
    "                **{k: round(v,3) for k,v in metrics.items()},\n",
    "                \"elapsed_time\": round(elapsed_time, 1),\n",
    "            }\n",
    "\n",
    "            res_df = pd.DataFrame([res_dict])\n",
    "            csv_path = \"results.csv\"\n",
    "            append = os.path.exists(csv_path) and os.path.getsize(csv_path) > 0\n",
    "            res_df.to_csv(csv_path, mode='a', header=not append, index=False)\n",
    "\n",
    "        print(model_name)\n",
    "        print(f\"P@10    {metrics['P@10']:.3f}\")\n",
    "        print(f\"R@10    {metrics['R@10']:.3f}\")\n",
    "        print(f\"MRR@10  {metrics['MRR@10']:.3f}\")\n",
    "        print(f\"nDCG@10 {metrics['nDCG@10']:.3f}\")\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== [1/14] ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 40221/40221 [00:22<00:00, 1796.59 examples/s]\n",
      "Map: 100%|██████████| 4719/4719 [00:01<00:00, 3173.14 examples/s]\n",
      "100%|██████████| 315/315 [00:00<00:00, 4474.16it/s]\n",
      "100%|██████████| 315/315 [00:00<00:00, 4833.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-MiniLM-L6-v2\n",
      "P@10    0.284\n",
      "R@10    0.373\n",
      "MRR@10  0.631\n",
      "nDCG@10 0.461\n",
      "==================== [2/14] ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 40221/40221 [00:27<00:00, 1463.20 examples/s]\n",
      "Map: 100%|██████████| 4719/4719 [00:02<00:00, 2091.09 examples/s]\n",
      "100%|██████████| 315/315 [00:00<00:00, 4397.14it/s]\n",
      "100%|██████████| 315/315 [00:00<00:00, 4910.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-MiniLM-L12-v2\n",
      "P@10    0.270\n",
      "R@10    0.351\n",
      "MRR@10  0.605\n",
      "nDCG@10 0.436\n",
      "==================== [3/14] ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 40221/40221 [01:31<00:00, 437.44 examples/s]\n",
      "Map: 100%|██████████| 4719/4719 [00:03<00:00, 1452.23 examples/s]\n",
      "100%|██████████| 315/315 [00:00<00:00, 2995.51it/s]\n",
      "100%|██████████| 315/315 [00:00<00:00, 3078.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-mpnet-base-v2\n",
      "P@10    0.271\n",
      "R@10    0.352\n",
      "MRR@10  0.599\n",
      "nDCG@10 0.437\n",
      "==================== [4/14] ====================\n",
      "Failed to embed nomic-ai/nomic-embed-text-v1.5: nomic-ai/nomic-bert-2048 You can inspect the repository content at https://hf.co/nomic-ai/nomic-embed-text-v1.5.\n",
      "Please pass the argument `trust_remote_code=True` to allow custom code to be run.\n",
      "==================== [5/14] ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 40221/40221 [00:43<00:00, 920.26 examples/s] \n",
      "Map: 100%|██████████| 4719/4719 [00:02<00:00, 2105.11 examples/s]\n",
      "100%|██████████| 315/315 [00:00<00:00, 4960.52it/s]\n",
      "100%|██████████| 315/315 [00:00<00:00, 4973.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAAI/bge-small-en-v1.5\n",
      "P@10    0.340\n",
      "R@10    0.450\n",
      "MRR@10  0.738\n",
      "nDCG@10 0.563\n",
      "==================== [6/14] ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 40221/40221 [01:34<00:00, 426.93 examples/s]\n",
      "Map: 100%|██████████| 4719/4719 [00:03<00:00, 1562.18 examples/s]\n",
      "100%|██████████| 315/315 [00:00<00:00, 3217.30it/s]\n",
      "100%|██████████| 315/315 [00:00<00:00, 3325.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAAI/bge-base-en-v1.5\n",
      "P@10    0.350\n",
      "R@10    0.463\n",
      "MRR@10  0.749\n",
      "nDCG@10 0.577\n",
      "==================== [7/14] ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 40221/40221 [03:48<00:00, 176.33 examples/s]\n",
      "Map: 100%|██████████| 4719/4719 [00:06<00:00, 748.99 examples/s]\n",
      "100%|██████████| 315/315 [00:00<00:00, 2743.48it/s]\n",
      "100%|██████████| 315/315 [00:00<00:00, 2700.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAAI/bge-large-en-v1.5\n",
      "P@10    0.356\n",
      "R@10    0.473\n",
      "MRR@10  0.755\n",
      "nDCG@10 0.589\n",
      "==================== [8/14] ====================\n",
      "Failed to embed Alibaba-NLP/gte-multilingual-base: Alibaba-NLP/new-impl You can inspect the repository content at https://hf.co/Alibaba-NLP/gte-multilingual-base.\n",
      "Please pass the argument `trust_remote_code=True` to allow custom code to be run.\n",
      "==================== [9/14] ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 40221/40221 [04:57<00:00, 135.20 examples/s]\n",
      "Map: 100%|██████████| 4719/4719 [00:06<00:00, 708.34 examples/s]\n",
      "100%|██████████| 315/315 [00:00<00:00, 2351.13it/s]\n",
      "100%|██████████| 315/315 [00:00<00:00, 2477.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake/snowflake-arctic-embed-l-v2.0\n",
      "P@10    0.320\n",
      "R@10    0.430\n",
      "MRR@10  0.713\n",
      "nDCG@10 0.535\n",
      "==================== [10/14] ====================\n",
      "Failed to embed jinaai/jina-embeddings-v3: No module named 'custom_st'\n",
      "==================== [11/14] ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 40221/40221 [01:34<00:00, 425.15 examples/s]\n",
      "Map: 100%|██████████| 4719/4719 [00:03<00:00, 1508.28 examples/s]\n",
      "100%|██████████| 315/315 [00:00<00:00, 2938.92it/s]\n",
      "100%|██████████| 315/315 [00:00<00:00, 3057.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intfloat/e5-base-v2\n",
      "P@10    0.341\n",
      "R@10    0.453\n",
      "MRR@10  0.739\n",
      "nDCG@10 0.565\n",
      "==================== [12/14] ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 40221/40221 [04:54<00:00, 136.44 examples/s]\n",
      "Map: 100%|██████████| 4719/4719 [00:06<00:00, 711.69 examples/s]\n",
      "100%|██████████| 315/315 [00:00<00:00, 2322.52it/s]\n",
      "100%|██████████| 315/315 [00:00<00:00, 2376.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAAI/bge-m3\n",
      "P@10    0.335\n",
      "R@10    0.448\n",
      "MRR@10  0.741\n",
      "nDCG@10 0.561\n",
      "==================== [13/14] ====================\n",
      "Failed to embed Lajavaness/bilingual-embedding-base: dangvantuan/bilingual_impl You can inspect the repository content at https://hf.co/Lajavaness/bilingual-embedding-base.\n",
      "Please pass the argument `trust_remote_code=True` to allow custom code to be run.\n",
      "==================== [14/14] ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  74%|███████▍  | 29808/40221 [05:43<01:59, 86.79 examples/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to embed Qwen/Qwen3-Embedding-0.6B: CUDA out of memory. Tried to allocate 2.74 GiB. GPU 0 has a total capacity of 31.37 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 29.85 GiB memory in use. Of the allocated memory 21.15 GiB is allocated by PyTorch, and 8.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T07:36:56.918990Z",
     "start_time": "2025-10-23T07:36:56.837404Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1381555b8fe67b50",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[43membedder\u001B[49m\n\u001B[32m      2\u001B[39m gc.collect()\n\u001B[32m      3\u001B[39m torch.cuda.empty_cache()        \n",
      "\u001B[31mNameError\u001B[39m: name 'embedder' is not defined"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
